# Awesome Video Inpainting [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

A list of video inpainting (VI) papers.

Any suggestions and requests are always welcomed :)



## Contents
> 1\. [VI Papers](#vi-papers)
>
> 2\. [Other Related Papers](#other-related-papers)
>
> 3\. [Popular Datasets](#popular-datasets)




## VI Papers
### 2025
- **[RGVI]** Elevating Flow-Guided Video Inpainting with Reference Generation, *AAAI* [[arXiv]](https://arxiv.org/abs/2412.08975) [[Code]](https://github.com/suhwan-cho/RGVI)

- **[FFF-VDI]** Video Diffusion Models are Strong Video Inpainter, *AAAI* [[arXiv]](https://arxiv.org/abs/2408.11402) [[Code]](https://github.com/Hydragon516/FFF-VDI)


### 2024
- **[LGVI]** Towards Language-Driven Video Inpainting via Multimodal Large Language Models, *CVPR* [[Paper]](https://openaccess.thecvf.com/content/CVPR2024/papers/Wu_Towards_Language-Driven_Video_Inpainting_via_Multimodal_Large_Language_Models_CVPR_2024_paper.pdf) [[arXiv]](https://arxiv.org/abs/2401.10226) [[Code]](https://github.com/jianzongwu/Language-Driven-Video-Inpainting)

- **[AVID]** AVID: Any-Length Video Inpainting with Diffusion Model, *CVPR* [[Paper]](https://openaccess.thecvf.com/content/CVPR2024/papers/Zhang_AVID_Any-Length_Video_Inpainting_with_Diffusion_Model_CVPR_2024_paper.pdf) [[arXiv]](https://arxiv.org/abs/2312.03816) [[Code]](https://github.com/zhang-zx/AVID)

- **[WaveFormer]** WaveFormer: Wavelet Transformer for Noise-Robust Video Inpainting, *AAAI* [[Paper]](https://ojs.aaai.org/index.php/AAAI/article/view/28435/28848)


### 2023
- **[SAVIT]** Semantic-Aware Dynamic Parameter for Video Inpainting Transformer, *ICCV* [[Paper]](https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Semantic-Aware_Dynamic_Parameter_for_Video_Inpainting_Transformer_ICCV_2023_paper.pdf) 

- **[CIRI]** CIRI: Curricular Inactivation for Residue-aware One-shot Video Inpainting, *ICCV* [[Paper]](https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_CIRI_Curricular_Inactivation_for_Residue-aware_One-shot_Video_Inpainting_ICCV_2023_paper.pdf) [[Code]](https://github.com/Arise-zwy/CIRI)

- **[ProPainter]** ProPainter: Improving Propagation and Transformer for Video Inpainting, *ICCV* [[Paper]](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_ProPainter_Improving_Propagation_and_Transformer_for_Video_Inpainting_ICCV_2023_paper.pdf) [[arXiv]](https://arxiv.org/abs/2309.03897) [[Code]](https://github.com/sczhou/ProPainter)

- **[SSVI]** Semi-Supervised Video Inpainting with Cycle Consistency Constraints, *CVPR* [[Paper]](https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_Semi-Supervised_Video_Inpainting_With_Cycle_Consistency_Constraints_CVPR_2023_paper.pdf) [[arXiv]](https://arxiv.org/abs/2208.06807)


### 2022
- **[FGT]** Flow-Guided Transformer for Video Inpainting, *ECCV* [[Paper]](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136780072.pdf) [[arXiv]](https://arxiv.org/abs/2208.06768) [[Code]](https://github.com/hitachinsk/FGT)

- **[ECFVI]** Error Compensation Framework for Flow-Guided Video Inpainting, *ECCV* [[Paper]](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136750373.pdf) [[arXiv]](https://arxiv.org/abs/2207.10391) [[Code]](https://github.com/JaeYeonKang/ECFVI)

- **[DeViT]** DeViT: Deformed Vision Transformers in Video Inpainting, *ACMMM* [[Paper]](https://dl.acm.org/doi/pdf/10.1145/3503161.3548395) [[arXiv]](https://arxiv.org/abs/2209.13925)

- **[E2FGVI]** Towards An End-to-End Framework for Flow-Guided Video Inpainting, *CVPR* [[Paper]](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Towards_an_End-to-End_Framework_for_Flow-Guided_Video_Inpainting_CVPR_2022_paper.pdf) [[arXiv]](https://arxiv.org/abs/2204.02663) [[Code]](https://github.com/MCG-NKU/E2FGVI)

- **[ISVI]** Inertia-Guided Flow Completion and Style Fusion for Video Inpainting, *CVPR* [[Paper]](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Inertia-Guided_Flow_Completion_and_Style_Fusion_for_Video_Inpainting_CVPR_2022_paper.pdf) [[Code]](https://github.com/hitachinsk/ISVI)

- **[DLFormer]** DLFormer: Discrete Latent Transformer for Video Inpaintin, *CVPR* [[Paper]](https://openaccess.thecvf.com/content/CVPR2022/papers/Ren_DLFormer_Discrete_Latent_Transformer_for_Video_Inpainting_CVPR_2022_paper.pdf) [[Code]](https://github.com/JingjingRenabc/dlformer)


### 2021
- **[IIVI]** Internal Video Inpainting by Implicit Long-range Propagation, *ICCV* [[Paper]](https://openaccess.thecvf.com/content/ICCV2021/papers/Ouyang_Internal_Video_Inpainting_by_Implicit_Long-Range_Propagation_ICCV_2021_paper.pdf) [[arXiv]](https://arxiv.org/abs/2108.01912) [[Code]](https://github.com/Tengfei-Wang/Implicit-Internal-Video-Inpainting)

- **[FuseFormer]** FuseFormer: Fusing Fine-Grained Information in Transformers for Video Inpainting, *ICCV* [[Paper]](https://openaccess.thecvf.com/content/ICCV2021/papers/Liu_FuseFormer_Fusing_Fine-Grained_Information_in_Transformers_for_Video_Inpainting_ICCV_2021_paper.pdf) [[arXiv]](https://arxiv.org/abs/2109.02974) [[Code]](https://github.com/ruiliu-ai/FuseFormer)

- **[VIST]** Flow-Guided Video Inpainting with Scene Templates, *ICCV* [[Paper]](https://openaccess.thecvf.com/content/ICCV2021/papers/Lao_Flow-Guided_Video_Inpainting_With_Scene_Templates_ICCV_2021_paper.pdf) [[arXiv]](https://arxiv.org/abs/2108.12845) [[Code]](https://github.com/donglao/videoinpainting)

- **[VOIN]** Occlusion-Aware Video Object Inpainting, *ICCV* [[Paper]](https://openaccess.thecvf.com/content/ICCV2021/papers/Ke_Occlusion-Aware_Video_Object_Inpainting_ICCV_2021_paper.pdf) [[arXiv]](https://arxiv.org/abs/2108.06765) [[Page]](http://www.kelei.site/voin/)

- **[TSAM]** Progressive Temporal Feature Alignment Network for Video Inpainting, *CVPR* [[Paper]](https://openaccess.thecvf.com/content/CVPR2021/papers/Zou_Progressive_Temporal_Feature_Alignment_Network_for_Video_Inpainting_CVPR_2021_paper.pdf) [[arXiv]](https://arxiv.org/abs/2104.03507) [[Code]](https://github.com/MaureenZOU/TSAM)


### 2020
- **[CANet]** Short-Term and Long-Term Context Aggregation Network for Video Inpainting, *ECCV* [[Paper]](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123490698.pdf) [[arXiv]](https://arxiv.org/abs/2009.05721)

- **[PVC]** Proposal-based Video Completion, *ECCV* [[Paper]](https://www.cs.utexas.edu/~grauman/papers/eccv2020-hu.pdf)

- **[STTN]** Learning Joint Spatial-Temporal Transformations for Video Inpainting, *ECCV* [[Paper]](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123610511.pdf) [[arXiv]](https://arxiv.org/abs/2007.10247) [[Code]](https://github.com/researchmm/STTN)

- **[FGVC]** Flow-edge Guided Video Completion, *ECCV* [[Paper]](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123570698.pdf) [[arXiv]](https://arxiv.org/abs/2009.01835) [[Code]](https://github.com/vt-vl-lab/FGVC)


### 2019
- **[LGTSM]** Learnable Gated Temporal Shift Module for Deep Video Inpainting, *BMVC* [[Paper]](https://bmvc2019.org/wp-content/uploads/papers/0355-paper.pdf) [[arXiv]](https://arxiv.org/abs/1907.01131) [[Code]](https://github.com/amjltc295/Free-Form-Video-Inpainting)

- **[FVI]** Free-form Video Inpainting with 3D Gated Convolution and Temporal PatchGAN, *ICCV* [[Paper]](https://openaccess.thecvf.com/content_ICCV_2019/papers/Chang_Free-Form_Video_Inpainting_With_3D_Gated_Convolution_and_Temporal_PatchGAN_ICCV_2019_paper.pdf) [[arXiv]](https://arxiv.org/abs/1904.10247) [[Code]](https://github.com/amjltc295/Free-Form-Video-Inpainting)

- **[OPN]** Onion-Peel Networks for Deep Video Completion, *ICCV* [[Paper]](https://openaccess.thecvf.com/content_ICCV_2019/papers/Oh_Onion-Peel_Networks_for_Deep_Video_Completion_ICCV_2019_paper.pdf) [[arXiv]](https://arxiv.org/abs/1908.08718) [[Code]](https://github.com/seoungwugoh/opn-demo)

- **[CPNet]** Copy-and-Paste Networks for Deep Video Inpainting, *ICCV* [[Paper]](https://openaccess.thecvf.com/content_ICCV_2019/papers/Lee_Copy-and-Paste_Networks_for_Deep_Video_Inpainting_ICCV_2019_paper.pdf) [[arXiv]](https://arxiv.org/abs/1908.11587) [[Code]](https://github.com/shleecs/Copy-and-Paste-Networks-for-Deep-Video-Inpainting)

- **[InterVI]** An Internal Learning Approach to Video Inpainting, *ICCV* [[Paper]](https://openaccess.thecvf.com/content_ICCV_2019/papers/Zhang_An_Internal_Learning_Approach_to_Video_Inpainting_ICCV_2019_paper.pdf) [[arXiv]](https://arxiv.org/abs/1909.07957) [[Code]](https://github.com/Haotianz94/IL_video_inpainting)

- **[VINet]** Deep Video Inpainting, *CVPR* [[Paper]](https://openaccess.thecvf.com/content_CVPR_2019/papers/Kim_Deep_Video_Inpainting_CVPR_2019_paper.pdf) [[arXiv]](https://arxiv.org/abs/1905.01639) [[Code]](https://github.com/mcahny/Deep-Video-Inpainting)

- **[DFVI]** Deep Flow-Guided Video Inpainting, *CVPR* [[Paper]](https://openaccess.thecvf.com/content_CVPR_2019/papers/Xu_Deep_Flow-Guided_Video_Inpainting_CVPR_2019_paper.pdf) [[arXiv]](https://arxiv.org/abs/1905.02884) [[Code]](https://github.com/nbei/Deep-Flow-Guided-Video-Inpainting)

- **[CombCN]** Video Inpainting by Jointly Learning Temporal Structure and Spatial Details, *AAAI* [[Paper]](https://ojs.aaai.org/index.php/AAAI/article/view/4458/4336) [[arXiv]](https://arxiv.org/abs/1806.08482)






## Other Related Papers
### 2024
- **[DAEVI]** Depth-Aware Endoscopic Video Inpainting, *MICCAI* [[Paper]](https://papers.miccai.org/miccai-2024/paper/0179_paper.pdf) [[arXiv]](https://arxiv.org/abs/2407.02675) [[Code]](https://github.com/FrancisXZhang/DAEVI)

- **[BIVDiff]** BIVDiff: A Training-Free Framework for General-Purpose Video Synthesis via Bridging Image and Video Diffusion Models, *CVPR* [[Paper]](https://openaccess.thecvf.com//content/CVPR2024/papers/Shi_BIVDiff_A_Training-Free_Framework_for_General-Purpose_Video_Synthesis_via_Bridging_CVPR_2024_paper.pdf) [[arXiv]](https://arxiv.org/abs/2312.02813) [[Code]](https://github.com/MCG-NJU/BIVDiff)


### 2023
- **[BSCVR]** Bitstream-Corrupted Video Recovery: A Novel Benchmark Dataset and Method, *NeurIPS* [[Paper]](https://proceedings.neurips.cc/paper_files/paper/2023/file/d7928f6dfb0c30d6a6917587dacbe4bc-Paper-Datasets_and_Benchmarks.pdf) [[arXiv]](https://arxiv.org/abs/2309.13890) [[Code]](https://github.com/LIUTIGHE/BSCV-Dataset)

- **[SVINet]** Deep Stereo Video Inpainting, *CVPR* [[Paper]](https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_Deep_Stereo_Video_Inpainting_CVPR_2023_paper.pdf)

- **[DINet]** DINet: Deformation Inpainting Network for Realistic Face Visually Dubbing on High Resolution Video, *AAAI* [[Paper]](https://ojs.aaai.org/index.php/AAAI/article/download/25464/25236) [[arXiv]](https://arxiv.org/abs/2303.03988) [[Code]](https://github.com/MRzzm/DINet)


### 2022
- **[DEVIL]** The DEVIL is in the Details: A Diagnostic Evaluation Benchmark for Video Inpainting, *CVPR* [[Paper]](https://openaccess.thecvf.com/content/CVPR2022/papers/Szeto_The_DEVIL_Is_in_the_Details_A_Diagnostic_Evaluation_Benchmark_CVPR_2022_paper.pdf) [[arXiv]](https://arxiv.org/abs/2105.05332) [[Code]](https://github.com/MichiganCOG/devil)


### 2021
- **[FAST]** Frequency-Aware Spatiotemporal Transformers for Video Inpainting Detection, *ICCV* [[Paper]](https://openaccess.thecvf.com/content/ICCV2021/papers/Yu_Frequency-Aware_Spatiotemporal_Transformers_for_Video_Inpainting_Detection_ICCV_2021_paper.pdf)


### 2020
- **[DVI]** DVI: Depth Guided Video Inpainting for Autonomous Driving, *ECCV* [[Paper]](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123660001.pdf) [[arXiv]](https://arxiv.org/abs/2007.08854) [[Code]](https://github.com/sibozhang/Depth-Guided-Inpainting)


### 2019
- **[VORNet]** VORNet: Spatio-temporally Consistent Video Inpainting for Object Removal, *CVPRW* [[Paper]](https://openaccess.thecvf.com/content_CVPRW_2019/papers/NTIRE/Chang_VORNet_Spatio-Temporally_Consistent_Video_Inpainting_for_Object_Removal_CVPRW_2019_paper.pdf) [[arXiv]](https://arxiv.org/abs/1904.06726)

- **[BVDNet]** Deep Blind Video Decaptioning by Temporal Aggregation and Recurrence, *CVPR* [[Paper]](https://openaccess.thecvf.com/content_CVPR_2019/papers/Kim_Deep_Blind_Video_Decaptioning_by_Temporal_Aggregation_and_Recurrence_CVPR_2019_paper.pdf) [[arXiv]](https://arxiv.org/abs/1905.02949) [[Code]](https://github.com/mcahny/Deep_Blind_Video_Decaptioning)







## Popular Datasets
- **[DAVIS]** Densely Annotated VIdeo Segmentation Dataset [[Page]](https://davischallenge.org/)

- **[YouTube-VOS]** A Large-Scale Benchmark for Video Object Segmentation Dataset [[Page]](https://youtube-vos.org/)

- **[FVI]** Free-Form Video Inpainting Dataset [[Page]](https://github.com/amjltc295/Free-Form-Video-Inpainting)
